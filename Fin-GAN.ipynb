{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNJId6rKm4LPgpyzY5jfHw2"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":40,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gqv4Bs-H2sT5","executionInfo":{"status":"ok","timestamp":1720957734978,"user_tz":-540,"elapsed":191356,"user":{"displayName":"김재환","userId":"03265372797982411513"}},"outputId":"bc3ddef3-c6af-42e5-faa5-ae2762d5284c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch [10/100], D Loss: 1.3863, G Loss: -1.3789\n","Epoch [20/100], D Loss: 1.3863, G Loss: -1.0762\n","Epoch [30/100], D Loss: 1.3863, G Loss: -1.2458\n","Epoch [40/100], D Loss: 1.3863, G Loss: -2.1581\n","Epoch [50/100], D Loss: 1.3863, G Loss: -0.8275\n","Epoch [60/100], D Loss: 1.3863, G Loss: -2.1868\n","Epoch [70/100], D Loss: 1.3863, G Loss: -1.9265\n","Epoch [80/100], D Loss: 1.3863, G Loss: -1.8041\n","Epoch [90/100], D Loss: 1.3863, G Loss: -1.7253\n","Epoch [100/100], D Loss: 1.3863, G Loss: -1.4139\n","예측값: 0.5022321343421936\n","실제값: -0.006826336961239576\n"]}],"source":["import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader\n","\n","# 데이터 생성 및 데이터셋 클래스 (이전 코드와 동일)\n","def generate_stock_data(n_samples, seq_length, n_features=1):\n","    data = np.zeros((n_samples, seq_length, n_features))\n","    for i in range(n_samples):\n","        price = 100 * np.ones(seq_length + 1)\n","        returns = np.random.normal(0, 0.01, seq_length)\n","        price[1:] = price[0] * np.exp(np.cumsum(returns))\n","        log_returns = np.diff(np.log(price))\n","        data[i, :, 0] = log_returns\n","    return data\n","\n","class StockDataset(Dataset):\n","    def __init__(self, data, input_window, target_window):\n","        self.data = torch.FloatTensor(data)\n","        self.input_window = input_window\n","        self.target_window = target_window\n","\n","    def __len__(self):\n","        return len(self.data) - self.input_window - self.target_window + 1\n","\n","    def __getitem__(self, idx):\n","        x = self.data[idx:idx+self.input_window]\n","        y = self.data[idx+self.input_window:idx+self.input_window+self.target_window]\n","        return x, y\n","\n","# Generator 네트워크\n","class Generator(nn.Module):\n","    def __init__(self, condition_dim, noise_dim, hidden_dim, output_dim):\n","        super(Generator, self).__init__()\n","        self.condition_fc = nn.Linear(condition_dim, hidden_dim)\n","        self.noise_fc = nn.Linear(noise_dim, hidden_dim)\n","        self.lstm = nn.LSTM(hidden_dim * 2, hidden_dim, batch_first=True)\n","        self.fc = nn.Linear(hidden_dim, output_dim)\n","        self.sigmoid = nn.Sigmoid()\n","\n","    def forward(self, condition, noise):\n","        batch_size = condition.size(0)\n","        seq_len = condition.size(1)\n","\n","        # Flatten and process condition\n","        flat_condition = condition.view(batch_size, -1)\n","        # Remove the extra dimension from flat_condition\n","        flat_condition = flat_condition[:, :condition_dim]\n","        condition_hidden = self.condition_fc(flat_condition)\n","        condition_hidden = condition_hidden.unsqueeze(1).repeat(1, seq_len, 1)\n","\n","        # Process noise\n","        noise_hidden = self.noise_fc(noise)\n","        noise_hidden = noise_hidden.unsqueeze(1).repeat(1, seq_len, 1)\n","\n","        # Combine condition and noise\n","        combined = torch.cat([condition_hidden, noise_hidden], dim=-1)\n","\n","        lstm_out, _ = self.lstm(combined)\n","        return self.sigmoid(self.fc(lstm_out[:, -1, :])) # Apply sigmoid to the output\n","\n","# Discriminator 네트워크\n","class Discriminator(nn.Module):\n","    def __init__(self, input_dim, hidden_dim):\n","        super(Discriminator, self).__init__()\n","        self.lstm = nn.LSTM(input_dim, hidden_dim, batch_first=True)\n","        self.fc = nn.Linear(hidden_dim, 1)\n","\n","    def forward(self, x):\n","        lstm_out, _ = self.lstm(x)\n","        return torch.sigmoid(self.fc(lstm_out[:, -1, :]))\n","\n","# Fin-GAN 손실 함수\n","def fin_gan_loss(pred, target, pnl_weight=1.0, mse_weight=1.0, sr_weight=1.0):\n","    # Reshape target to match pred and scale to [0, 1]\n","    target = target.squeeze()[:, -1].unsqueeze(1)\n","    target = (target - target.min()) / (target.max() - target.min()) # Scale target to [0, 1]\n","\n","    bce_loss = nn.BCELoss()(pred, target)\n","    pnl_loss = -torch.mean(torch.tanh(100 * pred) * target)\n","    mse_loss = nn.MSELoss()(pred, target)\n","\n","    mean_pnl = torch.mean(torch.tanh(100 * pred) * target)\n","    std_pnl = torch.std(torch.tanh(100 * pred) * target)\n","    sr_loss = -mean_pnl / (std_pnl + 1e-6)\n","\n","    return bce_loss + pnl_weight * pnl_loss + mse_weight * mse_loss + sr_weight * sr_loss\n","\n","# 하이퍼파라미터 설정\n","n_samples = 1000\n","seq_length = 60\n","input_window = 50\n","target_window = 1\n","hidden_dim = 64\n","noise_dim = 10\n","num_epochs = 100\n","batch_size = 32\n","lr = 0.0001\n","\n","# 데이터 생성 및 준비\n","data = generate_stock_data(n_samples, seq_length)\n","dataset = StockDataset(data, input_window, target_window)\n","dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n","\n","# 모델 초기화\n","condition_dim = input_window * 1  # 50 * 1\n","generator = Generator(condition_dim, noise_dim, hidden_dim, target_window)\n","discriminator = Discriminator(input_dim=input_window, hidden_dim=hidden_dim)\n","\n","# 최적화기 초기화\n","g_optimizer = optim.Adam(generator.parameters(), lr=lr)\n","d_optimizer = optim.Adam(discriminator.parameters(), lr=lr)\n","\n","# 훈련 루프\n","for epoch in range(num_epochs):\n","    for condition, real_data in dataloader:\n","        batch_size = condition.size(0)\n","\n","        # Discriminator 훈련\n","        noise = torch.randn(batch_size, noise_dim)\n","        fake_data = generator(condition, noise)\n","\n","        # Reshape condition to 3D before passing to discriminator, taking only the input_window timesteps\n","        real_output = discriminator(condition[:, :, :input_window].view(batch_size, input_window, -1))\n","        fake_output = discriminator(condition[:, :, :input_window].view(batch_size, input_window, -1))\n","\n","        d_loss = nn.BCELoss()(real_output, torch.ones_like(real_output)) + \\\n","                nn.BCELoss()(fake_output, torch.zeros_like(fake_output))\n","\n","        d_optimizer.zero_grad()\n","        d_loss.backward()\n","        d_optimizer.step()\n","\n","        # Generator 훈련\n","        noise = torch.randn(batch_size, noise_dim)\n","        fake_data = generator(condition, noise)\n","        # Reshape condition to 3D before passing to discriminator, taking only the input_window timesteps\n","        fake_output = discriminator(condition[:, :, :input_window].view(batch_size, input_window, -1))\n","\n","        g_loss = fin_gan_loss(fake_data, real_data)\n","\n","        g_optimizer.zero_grad()\n","        g_loss.backward()\n","        g_optimizer.step()\n","\n","    if (epoch + 1) % 10 == 0:\n","        print(f\"Epoch [{epoch+1}/{num_epochs}], D Loss: {d_loss.item():.4f}, G Loss: {g_loss.item():.4f}\")\n","\n","# 모델 평가 (간단한 예시)\n","generator.eval()\n","with torch.no_grad():\n","    test_condition = dataset[0][0].unsqueeze(0)  # 첫 번째 샘플의 입력 데이터\n","    test_noise = torch.randn(1, noise_dim)\n","    predicted = generator(test_condition, test_noise)\n","    print(\"예측값:\", predicted.item())\n","    print(\"실제값:\", dataset[0][1][:, -1].item()) # Extract the last element of the target for the given timestep"]}]}